metallica<-c("Lars","James","Jason","Kirk")
metalica
print(metallica)
metallica<-metallica[metallica!= "Jason"]
metallica
metallica<-c(metallica, "Rob")
metallica
friends<-c(friends, "Mille", "Nina", "Kiri", "Jacob")
friends<-c("Mille","Nina","Kiri","Jacob")
friends
friends<-c("Mille","Nina","Kiri","Jacob")
friends<-friends[]
friends<-friends[!= "Jacob"]
friends<-friends[friends!= "Jacob"]
friends
friends<-c(friends, "Jacob")
friends
metallica
metallica
friends
friends<-friends[friends != "Jacob]
"]
friends
friends<-friends[friends != "Jacob"]
friends
friends<-friends[friends!= "Jacob"]
friends
friends<-c(friends, "Jacob")
friends
metallicaNames<-c("Lars","James","Kirk","Rob")
metallicaNames
metallicaAges<-c(47, 47, 48, 46)
metallicaAges
metallica<-data.frame(Name = metallicaNames, Age = metallicaAges)
metallica
metallica$Name
metallica$Age
metallica$childAge<-c(12, 12, 4, 6)
metallica$childAge
metallica
names(metallica)
metallica$fatherhoodAge<- metallica$Age & minus metallica$childAge
metallica$fatherhoodAge<- metallica$Age & - metallica$childAge
fatherhoodAge
metallica
metallica$fatherhoodAge<- metallica$Age - metallica$childAge
metallica
metallicaNames<-c("Lars","James","Kirk","Rob")
metallicaNames
metallicaAges<-c(47, 47, 48, 46)
metallicaAges
metallica<-data.frame(Name = metallicaNames, Age = metallicaAges)
metallica$Age
metallica$childAge<-c(12, 12, 4, 6)
metallica$childAge
metallica
names(metallica)
metallica$fatherhoodAge<- metallica$Age - metallica$childAge
name<-c("Ben", "Martin", "Andy", "Paul", "Graham", "Carina", "Karina", "Doug", "Mark", "Zoe")
husband<-as.Date(c("1973-06-21", "1970-07-16", "1949-10-08", "1969-05-24"))
wife<-as.Date(c("1984-11-12", "1973-08-02", "1948-11-11", "1983-07-23"))
agegap<-husband-wife
agegap
birth_date<-as.Date(c("1977-07-03", "1969-05-24", "1973-06-21","1970-07-16", "1949-10-10", "1983-11-05", "1987-10-08", "1989-09-16","1973-05-20", "1984-11-12"))
job<-c(1,1,1,1,1,2,2,2,2,2)
job
job<-factor(job, levels = c(1:2), labels = c("Lecturer", "Student"))
job<-gl(2, 5, labels = c("Lecturer", "Student"))
levels(job)
levels(job)<-c("Medical Lecturer", "Medical Student")
friends<-c(5,2,0,4,1,10,12,15,12,17)
alcohol<-c(10,15,20,5,30,25,20,16,17,18)
income<-c(20000,40000,35000,22000,50000,5000,100,3000,10000,10)
neurotic<-c(10,17,14,13,21,7,13,9,14,13)
lecturerData<-data.frame(name,birth_date,job,friends,alcohol,income,neurotic)
lecturerData
lecturerPersonality <- lecturerData[, c("friends", "alcohol","neurotic")]
lecturerPersonality
lecturerOnly <- lecturerData[job=="Medical Lecturer",]
lecturerOnly
alcoholPersonality <- lecturerData[alcohol > 10, c("friends","alcohol", "neurotic")]
alcoholPersonality
alcoholPersonalityMatrix <- as.matrix(alcoholPersonality)
alcoholPersonalityMatrix
alcoholPersonalityMatrix <- as.matrix(lecturerData[alcohol > 10,c("friends", "alcohol", "neurotic")])
alcoholPersonalityMatrix
satisfactionData = read.delim("Honeymoon Period.dat", header = TRUE)
satisfactionData = read.delim("Honeymoon Period.dat", header = TRUE)
satisfactionData = read.delim("Honeymoon Period.dat.txt", header = TRUE)
setwd("~/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio")
#Load data
search<- read.csv("~/Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
#Load data
search<- read.csv("~Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
#Load data
search<- read.csv("Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
#Load data
search<- read.csv("/Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
'% accuracy:'
mean(search$correct_resp,na.rm = TRUE)*100
#Load data
search<- read.csv("/Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
'% accuracy:'
mean(search$correct_resp,na.rm = TRUE)*100
#Remove NAs
search<-subset(search,search$rt!="NA")
search<-subset(search,search$correct_resp!=0)
#turn variables into factors
search$conjunct<-as.factor(search$conjunct)
search$present<-as.factor(search$present)
#Remove outliers
#search<-subset(search,search$rt<mean(search$rt)+3*sd(search$rt))
#histogram
hist(search$rt,breaks=10)
#Q-Q-plot
qqnorm(search$rt)
#make a log-transformation
search$logrt=log(search$rt)
#histogram
hist(search$logrt,breaks=10)
#Q-Q-plot
qqnorm(search$logrt)
search_model<-lm(logrt~setsize*conjunct*present, data=search)
summary(search_model)
library(ggplot2)
search$setsize_f<-as.factor(search$setsize)
ggplot(search, aes(x = setsize , y = rt, color=conjunct, fill=present)) +
geom_point() + labs(x = "setsize", y = "Response time)") +
geom_smooth(method='lm')
View(search)
sarah<- c(1.95,1.58,1.70,2.46,2.27,2.62,3.32,3.51,3.89,3.41)
mother<-c(3.21,4.04,3.30,3.85,4.13,4.59,4.11,4.29,5.82,5.14)
mean_sarah<-mean(sarah)
mean_mother<-mean(mother)
error_sarah<-sarah-mean_sarah
error_mother<-mother-mean_mother
error_sarah*error_mother
sum_of_scores<- sum(error_sarah*error_mother)
sum_of_scores
cov<-sum_of_scores/9
cov
SD_Sarah<-sqrt(mean_sarah)
cov
Correlation_coefficient<-cov/(0.82*0.79)
Correlation_coefficient
Correlation_coefficient*Correlation_coefficient
roh_squared<-Correlation_coefficient*Correlation_coefficient
Correlation_coefficient_aka_roh<-cov/(0.82*0.79)
install.packages("ggplot2"); install.packages("pastecs"); install.packages ("WRS")
library(ggplot2); library(pastecs); library(WRS)
install.packages ("WRS")
install.packages(“lme4”)
install.packages("lme4")
library(lme4)
politeness= read.csv("http://www.bodowinter.com/tutorial/politeness_data.csv")
View(politeness)
head(politeness)
tail(),
summary(politeness)
, str(),
colnames(politeness)
str(politeness),
colnames(politeness)
str(politeness),
colnames(politeness)
str(politeness)
which(is.na(politeness$frequency))
which(!complete.cases(politeness))
boxplot(frequency ~ attitude*gender,
col=c("white","lightgray"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("white","purple"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("red","purple"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("red","lightpurple"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("red","purple"),politeness)
lmer(frequency ~ attitude, data=politeness)
politeness.model = lmer(frequency ~ attitude + (1|subject) + (1|scenario), data=politeness)
summary(politeness.model)
politeness.model = lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), data=politeness)
summary(politeness.model)
politeness.null = lmer(frequency ~ gender +
(1|subject) + (1|scenario), data=politeness,
REML=FALSE)
politeness.null = lmer(frequency ~ gender + (1|subject) + (1|scenario), data=politeness,REML=FALSE)
politeness.model = lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), data=politeness, REML=FALSE)
anova(politeness.null,politeness.model)
coef(politeness.model)
politeness.model = lmer(frequency ~ attitude +
gender + (1+attitude|subject) +
(1+attitude|scenario),
data=politeness,
REML=FALSE)
coef(politeness.model)
politeness.null = lmer(frequency ~ gender + (1+attitude|subject) + (1+attitude|scenario), data=politeness, REML=FALSE)
anova(politeness.null,politeness.model)
library(pacman)
p_load(tidyverse, tm, stringr, tidytext)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/work/CLasswork/10 - Adam - Topic models/topic_models")
df <- read.csv("maga_lda.csv")
#Preprocessing partly taken from https://gist.github.com/bryangoodrich/7b5ef683ce8db592669e
#Partly from http://tidytextmining.com/nasa.html#topic-modeling
library(tidytext, stringr)
#df <- read.csv("maga_lda.csv")
tweet_to_corpus <- function(df){
my_stop_words <- c("nbsp", "amp", "gt", "lt","timesnewromanpsmt", "font","td", "li", "br", "tr", "quot","st", "img", "src", "strong", "http", "file", "files","https", "vcljjqvzb", "sxdoc", "maga", "https", "#maga", "MAGA", "#the", "the")
tidy_tweets <-df %>%
mutate(text = iconv(text, to = "ASCII//TRANSLIT"), #Convert to basic ASCII text to avoid silly characters
#Would make wierd ó's into o´s -> may conflict with Danish letters like Æ,Ø,Å
text = tolower(text),  # Converting to lower case
text = str_replace(text,"rt", " " ),  # Remove the "RT" (retweet) so duplicates are duplicates
text = str_replace(text,"@\\w+", " " ),  # Remove user names
text = str_replace(text,"http.+ |http.+$", " " ),  # Remove links
text = str_replace(text,"[[:punct:]]", " " ),  # Remove punctuation
text = str_replace(text,"[ |\t]{2,}", " " ),  # Remove tabs
text = str_replace(text,"amp", " " ),  # "&" is "&amp" in HTML, so after punctuation removed ...
text = str_replace(text,"^ ", "" ),  # Leading blanks
text = str_replace(text," $", "" ),
text = str_replace(text," +", " "))  # General spaces (should just do all whitespaces no?)) # Lagging blanks
corpus <- Corpus(VectorSource(df$text)) %>%  # Create corpus object - Easier for computer to work with
#Convinient to work with - doesn't use as much RAM
# Remove English stop words. This could be greatly expanded!
tm_map( removeWords, stopwords("en")) %>%
# Remove numbers. This could have been done earlier, of course.
tm_map(removeNumbers) %>%
# Stem the words. Google if you dont understand
tm_map(stemDocument) %>%
# Remove the stems associated with our search terms!
tm_map(removeWords, my_stop_words)  %>%
tm_map( removeWords, stopwords("en"))
return(corpus)
}
#tweet_to_corpus takes two arguments. 1 data frame, and a list of words you want removed.
tweet_corpus <- tweet_to_corpus(df)
install.packages("wordcloud")
install.packages("RColorBrewer")
library("wordcloud")
wordcloud(tweet_corpus, min.freq=2, max.words = 100, random.order = TRUE, col = brewer.pal(8, "Dark2"))
# Get the lengths and make sure we only create a DTM for tweets with
# some actual content
doc.lengths <- rowSums(as.matrix(DocumentTermMatrix(tweet_corpus)))
# Document Term Matrix
dtm <- DocumentTermMatrix(tweet_corpus[doc.lengths > 0])
burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
k <- 5
library("topicmodels")
Sys.time()
ldaOut <-LDA(dtm,k, method="Gibbs", control=list(nstart=nstart, seed = seed, best=best, burnin = burnin, iter = iter, thin=thin))
Sys.time()
ap_topics <- tidy(ldaOut, matrix = "beta")
ap_topics
View(ap_topics)
ap_top_terms <- ap_topics %>%
group_by(topic) %>%
top_n(10, beta) %>%
ungroup() %>%
arrange(topic, -beta)
ap_top_terms
View(ap_top_terms)
ap_top_terms %>%
mutate(term = reorder(term, beta)) %>%
ggplot(aes(term, beta, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~ topic, scales = "free") +
coord_flip()
lda_documents <- tidy(ldaOut, matrix = "gamma")
lda_documents
lda_documents <- tidy(ldaOut, matrix = "gamma")
lda_documents
View(lda_documents)
lda_documents <- tidy(ldaOut, matrix = "gamma")
lda_documents
lda_documents$tweet <- da$text
lda_documents$tweet <- df$text
lda_documents
# ```{r echo = false} = You only see the results in knitted file - For aflevering
lda_documents <- tidy(ldaOut, matrix = "gamma")
lda_documents
lda_documents$tweet <- df$text
lda_documents
lda_documents <- lda_documents %>%
mutate(topic = as.factor(topic),
interpreted_topic = recode(topic, "1" = "Float was a video of Trump floarting + resist + funni = Anti-Trump",
"2" = "Trump wishing thanksgiving + retweet",
"3" = "more Thanksgiving with Trump",
"4" = "common words",
"5" = "Appreciation"))
lda_documents
View(df)
lda_documents$tweet <- df$text
lda_documents
View(lda_documents)
View(lda_documents)
Document_subset1 <- filter(lda_documents$document == "1")
Document_subset1 <- filter(lda_documents, document == "1")
Document_subset1 <- filter(lda_documents, document == 1)
Document_subset1
coord_flip()
ggplot(Document_subset1 , aes(topic, gamma, fill = factor(topic))) +
geom_col(show.legend = FALSE) + coord_flip()
ggplot(Document_subset1 , aes(x = interpred_topic, y = gamma, fill = factor(topic))) +
geom_col(show.legend = FALSE) + coord_flip()
ggplot(Document_subset1 , aes(x = interpreted_topic, y = gamma, fill = factor(topic))) +
geom_col(show.legend = FALSE) + coord_flip()
